"""
RAG (Retrieval-Augmented Generation) —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –í–û–ö–ö–î–¶
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤
"""

import os
import json
from typing import List, Dict, Any, Optional
from knowledge_base import KnowledgeBase
from embedding_api import EmbeddingAPI, MockEmbeddingAPI


class RAGSystem:
    """RAG —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    
    def __init__(self, use_mock_embeddings: bool = False):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG-—Å–∏—Å—Ç–µ–º—ã"""
        self.knowledge_base = KnowledgeBase()
        
        if use_mock_embeddings:
            self.embedding_api = MockEmbeddingAPI()
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π API –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ Ollama
            try:
                self.embedding_api = EmbeddingAPI()
                print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama: {e}")
                print("‚úì –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –º–æ–∫–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
                self.embedding_api = MockEmbeddingAPI()
        
        self.documents_loaded = False
        print("‚úì RAG-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –í–û–ö–ö–î–¶ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def load_document(self, file_path: str) -> bool:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        try:
            if not os.path.exists(file_path):
                print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
                return False
            
            print(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {file_path}")
            success = self.knowledge_base.add_document_from_file(file_path, self.embedding_api)
            
            if success:
                self.documents_loaded = True
                stats = self.knowledge_base.get_stats()
                print(f"‚úì –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                print(f"  üìä –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['total_documents']}")
                print(f"  üìÑ –í—Å–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {stats['total_chunks']}")
                return True
            else:
                print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return False
    
    def search(self, query: str, k: int = 3) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        if not self.documents_loaded:
            print("‚ö†Ô∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞—è. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.")
            return []
        
        try:
            results = self.knowledge_base.search(query, self.embedding_api, top_k=k)
            
            formatted_results = []
            for result in results:
                formatted_results.append({
                    'content': result['document'].content,
                    'score': result['similarity'],
                    'metadata': result['document'].metadata
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
    
    def get_answer(self, query: str, k: int = 3) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∏—Å–∫–∞"""
        search_results = self.search(query, k=k)
        
        if not search_results:
            return {
                'answer': '–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –í–û–ö–ö–î–¶.',
                'sources': [],
                'confidence': 0.0
            }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        context = ""
        sources = []
        
        for i, result in enumerate(search_results):
            context += f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i+1}] {result['content']}\n\n"
            sources.append({
                'content': result['content'][:200] + '...' if len(result['content']) > 200 else result['content'],
                'score': result['score']
            })
        
        # –ü—Ä–æ—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤—ã–∑–æ–≤ LLM
        answer = self._generate_simple_answer(query, context)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ score'–æ–≤
        avg_score = sum(result['score'] for result in search_results) / len(search_results)
        confidence = min(avg_score * 1.2, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ 1.0
        
        return {
            'answer': answer,
            'sources': sources,
            'confidence': confidence
        }
    
    def _generate_simple_answer(self, query: str, context: str) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è LLM)"""
        # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤—ã–∑–æ–≤ LLM
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        lines = context.split('\n')
        relevant_lines = []
        
        for line in lines:
            if len(line.strip()) > 20:  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                relevant_lines.append(line.strip())
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        answer = f"–ù–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –í–û–ö–ö–î–¶:\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞—Å—Ç–∏
        for i, line in enumerate(relevant_lines[:4]):  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 4 —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            if i == 0:
                answer += f"‚Ä¢ {line}\n"
            else:
                answer += f"‚Ä¢ {line}\n"
        
        answer += f"\n–î–ª—è –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—É –í–û–ö–ö–î–¶ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É +7 (473) 272-02-05."
        
        return answer
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        return self.knowledge_base.get_stats()
    
    def clear_knowledge_base(self) -> bool:
        """–û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        try:
            self.knowledge_base.clear()
            self.documents_loaded = False
            print("‚úì –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –æ—á–∏—â–µ–Ω–∞")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
            return False